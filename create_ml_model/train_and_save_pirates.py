# -*- coding: utf-8 -*-
"""train_and_save_pirates.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1awNe0JEVucJDvSBLZODh8KIekjTO3-z0
"""

# train_and_save_model.ipynb

import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score
import joblib

# --------------------------------
# 1) Read the CSV data
# --------------------------------
df = pd.read_csv("pirates.csv")  # adjust file name/path

# Example column transformations (same as before)
def parse_base_move(move_str):
    if pd.isnull(move_str):
        return np.nan
    parts = re.split(r'\+|\s+', move_str.strip())
    total = 0
    for p in parts:
        p = p.upper()
        if p == 'S':
            total += 1
        elif p == 'L':
            total += 2
    return total

def parse_cannons(cannon_str):
    if pd.isnull(cannon_str):
        return (0, np.nan, 0.0)
    parts = re.split(r'[,\s]+', cannon_str.strip())
    ranks = []
    l_count = 0
    for part in parts:
        part = part.upper().strip()
        match = re.match(r'(\d+)([SL])', part)
        if match:
            rank_val = int(match.group(1))
            range_str = match.group(2)
            ranks.append(rank_val)
            if range_str == 'L':
                l_count += 1
    if len(ranks) > 0:
        avg_rank = np.mean(ranks)
        frac_L = l_count / len(ranks)
    else:
        avg_rank = np.nan
        frac_L = 0.0
    return (len(ranks), avg_rank, frac_L)

df["BaseMoveValue"] = df["Base Move"].apply(parse_base_move)
df["NumCannons"], df["AvgCannonRank"], df["FracL"] = zip(*df["Cannons"].apply(parse_cannons))

# Fill missing text in abilities so TF-IDF doesn't fail
df["Ability"] = df["Ability"].fillna("")

# Let's define our feature/target columns
numeric_cols = ["Masts", "Cargo", "BaseMoveValue", "NumCannons", "AvgCannonRank", "FracL"]
categorical_col = "Faction"
text_col = "Ability"
target_col = "Point Cost"

# Filter out rows missing target or required numeric data
df_model = df.dropna(subset=[target_col] + numeric_cols)

X = df_model[numeric_cols + [categorical_col, text_col]]
y = df_model[target_col]

# 2) Build the pipeline
from sklearn.compose import ColumnTransformer

numeric_transformer = Pipeline([
    ("scaler", StandardScaler())
])

categorical_transformer = OneHotEncoder(handle_unknown="ignore")

text_transformer = TfidfVectorizer(
    lowercase=True,
    stop_words="english",
    max_features=500
)

preprocessor = ColumnTransformer([
    ("num", numeric_transformer, numeric_cols),
    ("cat", categorical_transformer, [categorical_col]),
    ("txt", text_transformer, text_col)
])

model_pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("regressor", RandomForestRegressor(n_estimators=100, random_state=42))
])

# 3) Train/test split & fit
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model_pipeline.fit(X_train, y_train)

# 4) Evaluate
y_pred = model_pipeline.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("RandomForestRegressor results on test set:")
print("MAE:", mae)
print("R^2:", r2)

# 5) Save the pipeline to disk as a .pkl
joblib.dump(model_pipeline, "pirates_point_model.pkl")
print("Saved model pipeline to pirates_point_model.pkl")